############################################
# 2022-12-09
# 데이터운영팀
# Bigdata Cluster 구축용 Ansible 설정 파일
#
# 개발 장비용
############################################

## Ansible Home 디렉토리
ansible_home: "/home/bigdata/ansible"

## OS 사용자명
remote_user: "bigdata"

## Java Home 디렉토리
java_home: "/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.322.b06-11.el8.x86_64"

## 기본 홈 디렉토리
bigdata_home: "/opt/bigdata"

## 설치파일 디렉토리
installer_home: "/home/bigdata/install"

## 서비스별 설치파일
installer:
  sshfs: "fuse-sshfs-2.8-7.el8.x86_64.rpm"
  zookeeper: "apache-zookeeper-3.6.3-bin.tar.gz"
  # Hadoop 3.3.4 Snappy dependency 이슈로 인한 버전 변경 (3.3.4 to 3.2.4)
  hadoop: "hadoop-3.2.4.tar.gz"
  kafka: "kafka_2.13-3.3.1.tgz"
  pyenv: "pyenv.tgz"
  python: "Python-3.10.8.tar.xz"
  pexpect: "pexpect.tgz"
  mariadb: "mariadb-10.6.11-linux-systemd-x86_64.tar.gz"
  mariadb_jdbc: "mariadb-java-client-2.7.7.jar"
  # Airflow MariaDB 미지원으로 인한 MetaDB 변경 (MariaDB 10.6.11 to MySQL 8.0.32)
  mysql: "mysql-8.0.32-linux-glibc2.12-x86_64.tar.xz"
#  mysql_jdbc: "mysql-connector-java-8.0.28.jar"
  mysql_jdbc: "mysql-connector-j-8.0.32.jar"
#  hive: "apache-hive-2.3.9-bin.tar.gz"
  hive: "apache-hive-3.1.2-bin.tar.gz"
  hive_spark: "spark-2.3.0-bin-hadoop2-without-hive.tgz"
  spark: "spark-3.3.1-bin-hadoop3-scala2.13.tgz"
  tez_min: "tez-0.10.1-minimal.tar.gz"
  tez: "tez-0.10.1.tar.gz"
#  tez_min: "tez-0.10.2-minimal-hadoop-3.2.0.tar.gz"
#  tez: "tez-0.10.2-hadoop-3.2.0.tar.gz"
  hbase: "hbase-2.5.2-hadoop3-bin.tar.gz"
  sqoop: "sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz"
  ojdbc: "ojdbc8-21.8.0.0.jar"
  jdk11: "openjdk-11_linux-x64_bin.tar.gz"
  hue: "hue-4.10.3.image"
  ufk: "kafka-ui-0.5.1.amd64.image"
  zeppelin: "zeppelin-0.11.0-SNAPSHOT.tar.gz"
  redis: "redis-7.0.8.tar.gz"
  R: "R-4.2.2.tar.gz"

## Zookeeper 설정
zookeeper:
  client_port: 12181
  data_dir: "/opt/bigdata/zookeeper/data"

  # 내부 통신용 포트
  internal_follower_port: 12888
  internal_leader_port: 13888

## Hadoop 설정
hadoop:
  hdfs:
    # Namenode HA Endpoint
    nameservice: "kdev-hdfs"

    # Namenode 설정 (해당 값을 변경하는 경우, Namenode format 필요, 주의)
    # (값이 1개인 경우에도 리스트 형식으로 기재)
    namenode_dir:
      - "/disk01/dfs/nn"
      - "/disk02/dfs/nn"
    namenode_rpc_port: 8020
    namenode_http_port: 50070

    # Datanode 설정 (값이 1개인 경우에도 리스트 형식으로 기재)
    datanode_dir:
      - "/disk01/dfs/dn"
      - "/disk02/dfs/dn"
      - "/disk03/dfs/dn"
      - "/disk04/dfs/dn"
      - "/disk05/dfs/dn"

    # Journalnode 설정 (단일 값만 사용 가능)
    journalnode_dir: "/disk03/dfs/jn"
    journalnode_shared_edits_port: 8485

    # HDFS 설정
    replication_factor: 3
    block_size: 134217728
    webhdfs_enabled: true
    permission_umask: "022"
    trash_interval: 1
    httpfs_port: 50071

  yarn:
    # Resourcemanager HA Endpoint
    cluster_id: "kdev-yarn"

    # Resourcemanager 설정
    resourcemanager_scheduler_port: 8030
    resourcemanager_resource_tracker_port: 8031
    resourcemanager_port: 8032
    resourcemanager_admin_port: 8033
    resourcemanager_webapp_port: 8088
    resourcemanager_webapp_https_port: 8090
    scheduler_min_allocation_mb: 1024
    scheduler_max_allocation_mb: 16384
    scheduler_increment_allocation_mb: 512
    scheduler_min_allocation_vcores: 1
    scheduler_max_allocation_vcores: 16
    scheduler_increment_allocation_vcores: 1

    # Mapreduce에서 사용할 Framework (e.g. yarn, classic, local)
    mapreduce_framework: "yarn"

    jobhistoryserver_port: 10020
    # 사용자가 접근할 Jobhistory Webserver port
    jobhistoryserver_http_port: 19888
    jobhistoryserver_https_port: 19890
    jobhistoryserver_admin_port: 10033

## Kafka 설정
kafka:
  log_dir: "/data/kafka"
  log_retention_hour: 72
  num_partition: 1
  topic_replication_factor: 1
  bootstrap_port: 19092
  controller_port: 19093
  jmx_port: 9999

## MariaDB 설정
mariadb:
  jdbc_port: 13306
  home_dir: &maria_home_dir "/home/bigdata/mariadb"
  data_dir: "/data/mariadb"
  socket_dir: *maria_home_dir
  max_conn: 8192
  root_pw: "bigdata123"
  char_set: "utf8"

## MySQL 설정
mysql:
  jdbc_port: 13307
  home_dir: &mysql_home_dir "/opt/bigdata/mysql"
  data_dir: "/data/mysql"
  socket_dir: *mysql_home_dir
  max_conn: 8192
  root_pw: "bigdata123"
  char_set: "utf8"

## Hive 설정
hive:
  metastore:
    db_pw: "bigdata123"
    metastore_port: 19083
    hive_server2_port: 10000
  spark:
    driver_memory: "4g"
    driver_cores: 2
    executor_memory: "16g"
    executor_cores: 4
    history:
      update_interval: "5s"
      ui_port: 50074
      cleaner:
        enabled: false
        interval: "1d"
        max_age: "90d"
        max_num: "Int.MaxValue"


## Hive on Tez 설정
tez:
  tez_container_size: 8192
  lib_dir: "/apps/tez/lib"

## Spark 설정
spark:
  driver_memory: "4g"
  driver_cores: 2
  executor_memory: "16g"
  executor_cores: 4
  history:
    update_interval: "5s"
    ui_port: 18088
    cleaner:
      enabled: false
      interval: "1d"
      max_age: "90d"
      max_num: "Int.MaxValue"

## HBase 설정
hbase:
  master_port: 60000
  master_info_port: 60010
  region_port: 60020
  region_info_port: 60030
  znode_parent: /hbase
  znode_rootserver: root-region-server
  session_timeout: 60000
  rpc_timeout: 60000
  client_write_buffer: 2097152
  client_pause: 100
  client_retries_number: 35
  client_scanner_caching: 100
  client_keyvalue_maxsize: 10485760
  client_primary_call_timeout_get: 10
  client_primary_call_timeout_multiget: 10

## Sqoop 설정
sqoop:

## Hue 설정
hue:
  database_name: hue
  database_id: hue
  database_pw: bigdata123

## UI for Apache Kafka 설정
ufk:
  web_port: 9000
  cluster_name: DEV_Kafka_Cluster

## Airflow 설정
airflow:
  db_name: airflow
  db_user: airflow
  db_pw: airflow123
  web_port: 50073
  # How often (in seconds) to scan the DAGs directory for new files.
  dag_dir_list_interval: 60

## Zeppelin 설정
zeppelin:
  admin_user: bigdata
  admin_pw: bigdata123
  web_port: 28080

## Redis 설정
redis:
  port: 16379
  sentinel_port: 26379