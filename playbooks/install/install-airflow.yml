---

- name: Install Airflow
  hosts: airflow
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Create temporary directory
      file:
        dest: "/home/{{ remote_user }}/airflow-tmp"
        state: directory
        owner: "{{ remote_user }}"
        group: "{{ remote_user }}"
    - name: Install mysql-devel
      become: yes
      yum:
        name:
          - "mysql-devel"
          - "cyrus-sasl-devel"
    - name: Copy installer
      copy:
        src: "{{ installer_home }}/airflow/{{ item }}"
        dest: "/home/{{ remote_user }}/airflow-tmp/"
      with_items:
        - "airflow-download.tgz"
        - "airflow_mysql_whls.tgz"
        - "Redis_whls.tgz"
        - "hive-operator.tgz"
    - name: Unzip whls
      unarchive:
        src: "/home/{{ remote_user }}/airflow-tmp/{{ item }}"
        dest: "/home/{{ remote_user }}/airflow-tmp/"
        remote_src: true
        owner: "{{ remote_user }}"
        group: "{{ remote_user }}"
      with_items:
        - "airflow-download.tgz"
        - "airflow_mysql_whls.tgz"
        - "Redis_whls.tgz"
        - "hive-operator.tgz"
    - name: Install Airflow
      pip:
        name: "apache-airflow[celery]==2.5.1"
        extra_args: "--no-index -f /home/{{ remote_user }}/airflow-tmp/airflow-download/airflow_whls"
        state: present
    - name: Install Airflow-MySQL
      pip:
        name: "apache-airflow[mysql]"
        extra_args: "--no-index -f /home/{{ remote_user }}/airflow-tmp/airflow_mysql_whls"
        state: present
    - name: Install Airflow-Redis
      pip:
        name: "Redis"
        extra_args: "--no-index -f /home/{{ remote_user }}/airflow-tmp/Redis"
        state: present
    - name: Install Airflow-Hive
      pip:
        name: "apache-airflow-providers-apache-hive"
        extra_args: "--no-index -f /home/{{ remote_user }}/airflow-tmp/hive-operator"
        state: present
    - name: Remove temporary directory
      file:
        dest: "/home/{{ remote_user }}/airflow-tmp"
        state: absent
    - name: Edit Airflow home directory
      lineinfile:
        path: "/home/{{ remote_user }}/.bashrc"
        regexp: "^#? *{{ item.key | regex_escape() }}="
        line: "{{ item.key }}={{ item.value }}"
      with_dict:
        "export AIRFLOW_HOME": "\"{{ airflow_home }}\""
    - name: Setup Airflow home directory
      command: "~/.pyenv/shims/airflow info"
    - name: Edit Airflow configuration
      lineinfile:
        path: "{{ airflow_home }}/airflow.cfg"
        regexp: "^{{ item.key | regex_escape() }} ="
        line: "{{ item.key }} = {{ item.value }}"
      with_dict:
        "default_timezone": "Asia/Seoul"
        "executor": "CeleryExecutor"
        "load_examples": "False"
        "sql_alchemy_conn": "mysql://{{ airflow.db_user }}:{{ airflow.db_pw }}@{{ groups['mysql'][0] }}:{{ mysql.jdbc_port }}/{{ airflow.db_name }}"
        "default_ui_timezone": "Asia/Seoul"
        "web_server_port": "{{ airflow.web_port }}"
        "broker_url": "{% for r in groups['redis'] %}{% if r != groups['redis'][0] %};{% endif %}sentinel://:{{ redis.requirepass }}@{{ r }}:{{ redis.sentinel_port }}{% endfor %}"
        "result_backend": "db+mysql://{{ airflow.db_user }}:{{ airflow.db_pw }}@{{ groups['mysql'][0] }}:{{ mysql.jdbc_port }}/{{ airflow.db_name }}"
        "flower_host": "{{ groups['airflow-celery-flower'][0] }}"
        "flower_port": "{{ airflow.flower_port }}"
        "dag_dir_list_interval": "{{ airflow.dag_dir_list_interval }}"
        "schedule_after_task_execution": "False"
        "parallelism": "{{ airflow.parallelism }}"
        "max_active_tasks_per_dag": "{{ airflow.max_active_tasks_per_dag }}"
        "max_active_runs_per_dag": "{{ airflow.max_active_runs_per_dag }}"
        "sql_alchemy_pool_size": "{{ airflow.sql_alchemy_pool_size }}"
        "sql_alchemy_max_overflow": "{{ airflow.sql_alchemy_max_overflow }}"
        "max_db_retries": "{{ airflow.max_db_retries }}"
        "logging_level": "{{ airflow.logging_level }}"
        "celery_logging_level": "{{ airflow.celery_logging_level }}"
        "celery_worker_concurrency": "{{ airflow.celery_worker_concurrency }}"
        "auth_backends": "{{ airflow.auth_backends }}"
    - name: Edit Airflow configuration (Redis sentinel master_name)
      lineinfile:
        path: "{{ airflow_home }}/airflow.cfg"
        line: "master_name = mymaster"
        insertafter: "# visibility_timeout ="

## MetaDB create db, user
- name: Setting up a MySQL Database
  hosts: mysql
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Create DB, User
      shell: |
        bin/mysql -uroot -p{{ mysql.root_pw }} --socket={{ mysql.socket_dir }}/mysql.sock -e "CREATE DATABASE if not exists {{ airflow.db_name }} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
        bin/mysql -uroot -p{{ mysql.root_pw }} --socket={{ mysql.socket_dir }}/mysql.sock -e "CREATE USER if not exists '{{ airflow.db_user }}'@'localhost' IDENTIFIED BY '{{ airflow.db_pw }}';"
        bin/mysql -uroot -p{{ mysql.root_pw }} --socket={{ mysql.socket_dir }}/mysql.sock -e "GRANT ALL PRIVILEGES ON {{ airflow.db_name }}.* TO '{{ airflow.db_user }}'@'localhost';"
      args:
        chdir: "{{ mysql.home_dir }}"
    - name: Create DB, User
      shell: |
        bin/mysql -uroot -p{{ mysql.root_pw }} --socket={{ mysql.socket_dir }}/mysql.sock -e "CREATE USER if not exists '{{ airflow.db_user }}'@'{{ item }}' IDENTIFIED BY '{{ airflow.db_pw }}';"
        bin/mysql -uroot -p{{ mysql.root_pw }} --socket={{ mysql.socket_dir }}/mysql.sock -e "GRANT ALL PRIVILEGES ON {{ airflow.db_name }}.* TO '{{ airflow.db_user }}'@'{{ item }}';"
      args:
        chdir: "{{ mysql.home_dir }}"
      with_items: "{{ groups['airflow'] }}"

## MetaDB init schema
- name: Init schema
  hosts: airflow-webserver
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Init schema
      command: "/home/{{ remote_user }}/.pyenv/shims/airflow db init"
    - name: Create user
      expect:
        command: "/home/{{ remote_user }}/.pyenv/shims/airflow users create --username {{ airflow.admin_id }} --firstname ingyeom --lastname kim --role Admin --email igkim@daou.co.kr"
        responses:
          'Password:': "{{ airflow.admin_pw }}"
          'Repeat for confirmation:': "{{ airflow.admin_pw }}"

## sshfs 라이브러리 설치 추가

## Connect shared directory with sshfs
#- name: Init sshfs
#  hosts: airflow-celery-worker:!airflow-webserver
#  remote_user: "{{ remote_user }}"
#  become: no
#  vars:
#    airflow_home: "{{ bigdata_home }}/airflow"
#  tasks:
#    - name: Create directory
#      file:
#        path: "{{ airflow_home }}/{{ item }}"
#        state: directory
#      with_items:
#        - "dags"
#        - "logs"
#        - "jar"
#        - "shell"
#    - name: Connect sshfs
#      mount:
#        src: "{{ remote_user }}@{{ groups['airflow-webserver'][0] }}:{{ airflow_home }}/{{ item }}"
#        name: "{{ airflow_home }}/{{ item }}"
#        fstype: "fuse.sshfs"
#        state: mounted
#        opts: "ro,umask=0644"
#      with_items:
#        - "dags"
#        - "logs"
#        - "jar"
#        - "shell"

## sshfs fstab 자동 설정 추가


## Start Webserver
- name: Start Airflow webserver
  hosts: airflow-webserver
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Check Airflow webserver
      shell: "/usr/bin/ps -ef | grep 'master \\[airflow-webserver\\]'"
      register: webserver_result
      failed_when: false
    - name: Remove pid file
      file:
        path: "{{ airflow_home }}/{{ item }}"
        state: absent
      with_items:
        - "airflow-webserver.pid"
        - "airflow-webserver-monitor.pid"
      when: '"master [airflow-webserver]" not in webserver_result.stdout'
    - name: Start Airflow webserver
      command: "~/.pyenv/shims/airflow webserver -D"
      when: '"master [airflow-webserver]" not in webserver_result.stdout'
    - name: Airflow webserver status
      debug:
        msg: Airflow webserver already running.
      when: '"master [airflow-webserver]" in webserver_result.stdout'

## Start Scheduler
- name: Start Airflow scheduler
  hosts: airflow-scheduler
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Check Airflow scheduler
      shell: "/usr/bin/ps -ef | grep -v grep | grep 'bin/airflow scheduler'"
      register: scheduler_result
      failed_when: false
    - name: Remove pid file
      file:
        path: "{{ airflow_home }}/airflow-scheduler.pid"
        state: absent
      when: '"airflow scheduler" not in scheduler_result.stdout'
    - name: Start Airflow scheduler
      command: "~/.pyenv/shims/airflow scheduler -D"
      when: '"airflow scheduler" not in scheduler_result.stdout'
    - name: Airflow scheduler status
      debug:
        msg: Airflow scheduler already running.
      when: '"airflow scheduler" in scheduler_result.stdout'

## Start Celery Flower
- name: Start Celery flower
  hosts: airflow-celery-flower
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Check Celery flower
      shell: "/usr/bin/ps -ef | grep -v grep | grep 'airflow celery flower'"
      register: flower_result
      failed_when: false
    - name: Remove pid file
      file:
        path: "{{ airflow_home }}/airflow-flower.pid"
        state: absent
      when: '"airflow celery flower" not in flower_result.stdout'
    - name: Start Celery flower
      command: "~/.pyenv/shims/airflow celery flower -D"
      when: '"airflow celery flower" not in flower_result.stdout'


## Start Celery Worker
- name: Start Celery worker
  hosts: airflow-celery-worker
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    airflow_home: "{{ bigdata_home }}/airflow"
  tasks:
    - name: Check Celery worker
      shell: "/usr/bin/ps -ef | grep -v grep | grep 'celery worker' | grep 'MainProcess'"
      register: worker_result
      failed_when: false
    - name: Remove pid file
      file:
        path: "{{ airflow_home }}/airflow-worker.pid"
        state: absent
      when: '"celery worker" not in worker_result.stdout'
    - name: Start Celery worker
      command: "~/.pyenv/shims/airflow celery worker -D"
      when: '"celery worker" not in worker_result.stdout'
