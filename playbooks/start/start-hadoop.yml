- name: Create NameNode directory
  hosts: namenode:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: yes
  become_method: sudo
  become_user: root
  tasks:
    - name: Create NameNode directory
      file:
        path: "{{ item }}"
        state: directory
        owner: "{{ remote_user }}"
        group: "{{ remote_user }}"
      loop: "{{ hadoop.hdfs.namenode_dir }}"

- name: Create DataNode directory
  hosts: datanode:worker:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: yes
  become_method: sudo
  become_user: root
  tasks:
    - name: Create DataNode directory
      file:
        path: "{{ item }}"
        state: directory
        owner: "{{ remote_user }}"
        group: "{{ remote_user }}"
      loop: "{{ hadoop.hdfs.datanode_dir }}"

- name: Create JournalNode directory
  hosts: journalnode:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: yes
  become_method: sudo
  become_user: root
  tasks:
    - name: Create JournalNode directory
      file:
        path: "{{ hadoop.hdfs.journalnode_dir }}"
        state: directory
        owner: "{{ remote_user }}"
        group: "{{ remote_user }}"

- name: Start JournalNode
  hosts: journalnode:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check journalnode jps
      command: "/usr/bin/jps"
      register: journalnode_jps
      failed_when: False
    - name: Start Journalnode
      command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/hdfs --daemon start journalnode &"
      when: '"JournalNode" not in journalnode_jps.stdout'
    - name: Journalnode status
      debug:
        msg: Journalnode already running.
      when: '"JournalNode" in journalnode_jps.stdout'

- name: Start NameNode, JournalNode, ZKFC
  hosts: "{{ groups['namenode'][0] }}:&{{ variable_host }}"
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Start NameNode, JournalNode, ZKFC
      command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/sbin/start-dfs.sh"

- name: Start DataNode
  hosts: datanode:worker:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check DataNode jps
      command: "/usr/bin/jps"
      register: datanode_jps
      failed_when: False
    - name: Start DataNode
      command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/hdfs --daemon start datanode"
      when: '"DataNode" not in datanode_jps.stdout'

- name: Start ResourceManager
  hosts: resourcemanager:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check ResourceManager jps
      command: "/usr/bin/jps"
      register: rm_jps
      failed_when: False
    - command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/yarn --daemon start resourcemanager"
      when: '"ResourceManager" not in rm_jps.stdout'

- name: Start NodeManager
  hosts: nodemanager:worker:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check NodeManager jps
      command: "/usr/bin/jps"
      register: nm_jps
      failed_when: False
    - command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/yarn --daemon start nodemanager"
      when: '"NodeManager" not in nm_jps.stdout'

- name: Start JobHistory Server
  hosts: jobhistoryserver:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check JobHistory Server jps
      command: "/usr/bin/jps"
      register: hs_jps
      failed_when: False
    - command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/mapred --daemon start historyserver"
      when: '"JobHistoryServer" not in hs_jps.stdout'

- name: Start httpfs
  hosts: httpfs:&{{ variable_host }}
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Check HttpFSServer jps
      command: "/usr/bin/jps"
      register: httpfs_jps
      failed_when: False
    - command: "/usr/bin/nohup {{ bigdata_home }}/hadoop/bin/hdfs --daemon start httpfs"
      when: '"HttpFSServerWebServer" not in httpfs_jps.stdout'