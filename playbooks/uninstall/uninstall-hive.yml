---

- name: Stop HiveServer2
  hosts: hive-server2
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    hive_home: "{{ bigdata_home }}/hive"
  tasks:
    - name: Find HiveServer2 Process ID
      shell: "/usr/bin/ps -ef | grep hive.service.server.HiveServer2 | grep -v grep | awk '{print $2}'"
      register: hive_server2_pid
      failed_when: false
    - name: Kill HiveServer2 Process
      command: "/usr/bin/kill -9 {{ hive_server2_pid.stdout }}"
      failed_when: false

- name: Stop Metastore
  hosts: metastore
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    hive_home: "{{ bigdata_home }}/hive"
  tasks:
    - name: Stop HCatalog server
      shell: "{{ hive_home }}/hcatalog/sbin/hcat_server.sh stop"
      failed_when: False

- name: Drop Hive Metastore Database
  hosts: mariadb
  remote_user: "{{ remote_user }}"
  become: no
  tasks:
    - name: Drop database
      command: "{{ mariadb.home_dir }}/bin/mysql --socket={{ mariadb.socket_dir }}/mysql.sock -e 'drop database metastore;'"
      failed_when: False
    - name: Delete user
      command: "{{ mariadb.home_dir }}/bin/mysql --socket={{ mariadb.socket_dir }}/mysql.sock -e \"drop user 'hive'@'{{ item }}';\""
      with_items: "{{ groups['metastore'] }}"
      failed_when: False

#- name: Remove Tez library
#  hosts: "{{ groups['datanode'][0] }}"
#  remote_user: "{{ remote_user }}"
#  become: no
#  tasks:
#    - name: Remove library directory
#      command: "{{ bigdata_home }}/hadoop/bin/hdfs dfs -rm -r -f {{ tez.lib_dir }}"

- name: Uninstall Hive and Hive_Spark
  hosts: bigdata
  become: no
  vars:
    hive_home: "{{ bigdata_home }}/hive"
  tasks:
    #  - name: Stop Hive Metastore
    #    command: "{{ hive_home }}/bin"
    #    failed_when: False
    - name: Remove directory
      file:
        path: "{{ item }}"
        state: absent
      with_items:
        - "{{ bigdata_home }}/{{ installer.hive.replace('.tar.gz', '') }}"
        - "{{ hive_home }}"
        - "{{ bigdata_home }}/{{ installer.hive_spark.replace('.tgz', '') }}"
      failed_when: False

- name: Remove Spark library in HDFS
  hosts: "{{ groups['namenode'][0] }}"
  remote_user: "{{ remote_user }}"
  become: no
  vars:
    hadoop_home: "{{ bigdata_home }}/hadoop"
  tasks:
    - name: Create Hive warehouse directory
      shell: "{{ item }}"
      with_items:
        - "{{ hadoop_home }}/bin/hdfs dfs -rm -r -f /hive-on-spark/archive"
      failed_when: false